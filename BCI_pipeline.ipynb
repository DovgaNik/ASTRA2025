{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5egdoeS1T6tW"
   },
   "source": [
    "# Complete BCI Processing Pipeline: Raw EEG → Neural Network Predictions\n",
    "\n",
    "This notebook demonstrates a complete brain-computer interface processing pipeline that takes raw EEG data and processes it through all stages to neural network predictions. It combines the data preprocessing techniques from Module 2 with the machine learning approaches from Module 3.\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Data Loading**: Load raw EEG data from PhysioNet EEGBCI dataset\n",
    "2. **Signal Preprocessing**: Apply filtering, artifact removal, and cleaning\n",
    "3. **Feature Extraction**: Extract meaningful features from clean EEG signals\n",
    "4. **Data Preparation**: Create labeled datasets for machine learning\n",
    "5. **Model Training**: Train both classical and neural network models\n",
    "6. **Evaluation**: Assess model performance and make predictions\n",
    "\n",
    "**Data Source**: PhysioNet EEG Motor Movement/Imagery Database\n",
    "**Task**: Motor imagery classification (left vs right hand imagination)\n",
    "**Application**: Real-time BCI control systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSrWEpDbT6tY"
   },
   "source": [
    "## Step 1: Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qF3hWb-ZT6tY",
    "outputId": "c1d5f5db-dd1b-423b-81f7-971b54a2f4f1",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:53:59.820583Z",
     "start_time": "2025-07-16T08:53:57.279115Z"
    }
   },
   "source": [
    "# Install required packages\n",
    "!pip install mne tensorflow scikit-learn seaborn\n",
    "\n",
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow warnings\n",
    "\n",
    "# MNE for EEG processing\n",
    "import mne\n",
    "from mne import concatenate_raws\n",
    "from mne.datasets import eegbci\n",
    "from mne import events_from_annotations\n",
    "\n",
    "# Signal processing\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, filtfilt, welch\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Visualization\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"BCI Processing Pipeline Environment Ready\")\n",
    "print(f\"MNE Version: {mne.__version__}\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(\"All dependencies loaded successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in ./.venv/lib/python3.13/site-packages (1.9.0)\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[31mERROR: No matching distribution found for tensorflow\u001B[0m\u001B[31m\r\n",
      "\u001B[0mBCI Processing Pipeline Environment Ready\n",
      "MNE Version: 1.9.0\n",
      "TensorFlow Version: 2.20.0-dev20250708\n",
      "NumPy Version: 2.3.1\n",
      "All dependencies loaded successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmY_LtdET6tZ"
   },
   "source": [
    "## Step 2: Raw EEG Data Loading\n",
    "\n",
    "Load authentic human brain data from the PhysioNet EEG Motor Movement/Imagery Database. This dataset contains EEG recordings from subjects performing motor imagery tasks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWTTdY5QT6tZ",
    "outputId": "d89e766d-782b-46d1-8f8b-da4a501535ad",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:00.170178Z",
     "start_time": "2025-07-16T08:53:59.873921Z"
    }
   },
   "source": [
    "# Dataset parameters\n",
    "subject = 1\n",
    "runs = [3, 7, 11, 4, 8, 12]  # MI runs: 3/7 = right hand, 4/8 = left hand\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets.eegbci import standardize\n",
    "from mne.io import concatenate_raws\n",
    "from mne import events_from_annotations\n",
    "\n",
    "try:\n",
    "    # download & load\n",
    "    raw_fnames = eegbci.load_data(subject, runs, path=\"data\")\n",
    "    raws = [mne.io.read_raw_edf(f, preload=True) for f in raw_fnames]\n",
    "    raw = concatenate_raws(raws)\n",
    "\n",
    "    # channel names & positions\n",
    "    standardize(raw)\n",
    "    montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "    raw.set_montage(montage, on_missing=\"ignore\", verbose=False)\n",
    "\n",
    "    # extract events\n",
    "    events, event_id = events_from_annotations(raw)\n",
    "    print(f\"Events: {len(events)} markers | Types: {list(event_id.keys())}\")\n",
    "\n",
    "    data_loaded = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Data loading issue: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Events: 180 markers | Types: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2HmxKLrT6tZ"
   },
   "source": [
    "## Step 3: Signal Preprocessing Pipeline\n",
    "\n",
    "Apply comprehensive signal cleaning techniques to remove artifacts and enhance brain signals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzf90bb-T6tZ",
    "outputId": "56e54cef-33d0-4ea6-de1d-3a192fb94a0c",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:00.950070Z",
     "start_time": "2025-07-16T08:54:00.188318Z"
    }
   },
   "source": [
    "# 1. Select & verify motor‐cortex channels\n",
    "motor_channels = ['C3', 'C4', 'Cz', 'FC3', 'FC4', 'CP3', 'CP4']\n",
    "available = [ch for ch in motor_channels if ch in raw.ch_names]\n",
    "if len(available) < 3:\n",
    "    available = raw.ch_names[:8]\n",
    "    print(f\"Using first 8 available channels: {available}\")\n",
    "else:\n",
    "    print(f\"Using motor-cortex channels: {available}\")\n",
    "\n",
    "raw_sel = raw.copy().pick_channels(available)\n",
    "\n",
    "# 2. Filtering: notch @50 Hz + band-pass 1–40 Hz\n",
    "raw_filt = raw_sel.copy()\n",
    "raw_filt.notch_filter(50., picks='eeg', fir_design='firwin')    # remove line noise\n",
    "raw_filt.filter(1., 40., picks='eeg', fir_design='firwin')      # delta–beta band\n",
    "\n",
    "print(\"Filters applied: notch 50 Hz & 1–40 Hz band-pass\")\n",
    "\n",
    "# 3. ICA artifact removal\n",
    "from mne.preprocessing import ICA\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "ica = ICA(n_components=0.99, method='fastica', random_state=42, max_iter='auto')\n",
    "ica.fit(raw_filt)  # fit ICA on filtered data\n",
    "\n",
    "# try EOG-based detection, else use kurtosis fallback\n",
    "try:\n",
    "    eog_inds, _ = ica.find_bads_eog(raw_filt)\n",
    "    ica.exclude = eog_inds\n",
    "    reason = f\"EOG comps {eog_inds}\"\n",
    "except RuntimeError:\n",
    "    comps = ica.get_sources(raw_filt).get_data()\n",
    "    kurt_vals = kurtosis(comps, axis=1)\n",
    "    n_art = min(2, comps.shape[0] // 3)\n",
    "    bads = np.argsort(np.abs(kurt_vals))[-n_art:]\n",
    "    ica.exclude = bads.tolist()\n",
    "    reason = f\"Kurtosis-based comps {bads.tolist()}\"\n",
    "\n",
    "raw_clean = ica.apply(raw_filt.copy())\n",
    "print(f\"ICA applied, excluded components: {ica.exclude} ({reason})\")\n",
    "\n",
    "# 4. Compute noise-reduction metric\n",
    "raw_data, clean_data = raw_sel.get_data(), raw_clean.get_data()\n",
    "noise_red = np.mean((np.std(raw_data,1) - np.std(clean_data,1))\n",
    "                    / np.std(raw_data,1) * 100)\n",
    "\n",
    "print(f\"Noise reduction: {noise_red:.1f}%\")\n",
    "print(f\"Signal quality: {'Excellent' if noise_red > 20 else 'Good'}\")\n",
    "\n",
    "# 5. Set up outputs for next steps\n",
    "sfreq = raw_clean.info['sfreq']\n",
    "times = np.arange(clean_data.shape[1]) / sfreq\n",
    "preprocessed_data = clean_data * 1e6   # to µV\n",
    "channel_names = available"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using motor-cortex channels: ['C3', 'C4', 'Cz', 'FC3', 'FC4', 'CP3', 'CP4']\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 6 contiguous segments\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Filtering raw data in 6 contiguous segments\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 529 samples (3.306 s)\n",
      "\n",
      "Filters applied: notch 50 Hz & 1–40 Hz band-pass\n",
      "Fitting ICA to data using 7 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by explained variance: 4 components\n",
      "Fitting ICA took 0.5s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (4 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 7 PCA components\n",
      "ICA applied, excluded components: [1] (Kurtosis-based comps [1])\n",
      "Noise reduction: 33.2%\n",
      "Signal quality: Excellent\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhxpPHE6T6tZ"
   },
   "source": [
    "## Step 4: Feature Extraction\n",
    "\n",
    "Extract meaningful features from the clean EEG signals that can be used for classification."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_N4lOYPT6tZ",
    "outputId": "1e73814a-05d2-4e66-9db7-6f4086f82c6b",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:01.338139Z",
     "start_time": "2025-07-16T08:54:01.040856Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from mne import events_from_annotations, Epochs\n",
    "from mne.time_frequency import psd_array_welch\n",
    "\n",
    "# 0. Build epochs with only our channels\n",
    "events, event_id = events_from_annotations(raw_clean)\n",
    "epochs = Epochs(\n",
    "    raw_clean, events, event_id,\n",
    "    tmin=-0.2, tmax=0.8, baseline=(None, 0),\n",
    "    preload=True\n",
    ").pick(channel_names)\n",
    "\n",
    "# 1. Compute PSD with Welch (adjust window to epoch length)\n",
    "data = epochs.get_data()            # (n_epochs, n_ch, n_times)\n",
    "sf   = epochs.info['sfreq']\n",
    "n_times = data.shape[-1]\n",
    "n_per_seg = min(256, n_times)\n",
    "n_overlap = n_per_seg // 2\n",
    "\n",
    "psds, freqs = psd_array_welch(\n",
    "    data, sf,\n",
    "    fmin=1, fmax=40,\n",
    "    n_fft=n_per_seg,\n",
    "    n_per_seg=n_per_seg,\n",
    "    n_overlap=n_overlap,\n",
    "    average='mean'\n",
    ")                                   # (n_epochs, n_ch, n_freqs)\n",
    "\n",
    "# 2. Precompute masks for bands\n",
    "bands = dict(delta=(1,4), theta=(4,8), alpha=(8,12), beta=(13,30), gamma=(30,40))\n",
    "band_masks = {b: np.logical_and(freqs>=lo, freqs<=hi) for b,(lo,hi) in bands.items()}\n",
    "\n",
    "# 3. Hjorth helper\n",
    "def hjorth(x):\n",
    "    dx = np.diff(x); ddx = np.diff(dx)\n",
    "    v0,v1,v2 = np.var(x), np.var(dx), np.var(ddx)\n",
    "    mob = np.sqrt(v1/v0) if v0 else 0\n",
    "    com = np.sqrt(v2/v1)/mob if v1 and mob else 0\n",
    "    return v0, mob, com\n",
    "\n",
    "# 4. Allocate feature array\n",
    "n_ep, n_ch, _ = psds.shape\n",
    "feats_per_ch = len(bands) + 2 + 5 + 1 + 1 + 3\n",
    "X = np.zeros((n_ep, n_ch * feats_per_ch), float)\n",
    "\n",
    "# 5. Fill features\n",
    "for ei in range(n_ep):\n",
    "    col = 0\n",
    "    sigs = data[ei]  # (n_ch, n_times)\n",
    "    for ci in range(n_ch):\n",
    "        sig = sigs[ci]\n",
    "        psd = psds[ei,ci]\n",
    "\n",
    "        # band powers\n",
    "        for b in bands:\n",
    "            m = band_masks[b]\n",
    "            X[ei,col] = np.trapz(psd[m], freqs[m]); col+=1\n",
    "\n",
    "        # ratios\n",
    "        a = X[ei,col-len(bands)+2]  # alpha\n",
    "        b_ = X[ei,col-len(bands)+3] # beta\n",
    "        X[ei,col]   = a/b_ if b_>0 else 0; col+=1\n",
    "        X[ei,col]   = X[ei,col-len(bands)+1]/b_ if b_>0 else 0; col+=1\n",
    "\n",
    "        # time‐domain\n",
    "        X[ei,col:col+5] = [\n",
    "            sig.mean(), sig.std(), sig.var(),\n",
    "            np.sqrt((sig**2).mean()),\n",
    "            sig.max()-sig.min()\n",
    "        ]; col += 5\n",
    "\n",
    "        # zero‐cross rate\n",
    "        X[ei,col] = np.sum(np.diff(np.signbit(sig))) / sig.size; col+=1\n",
    "\n",
    "        # spectral centroid\n",
    "        X[ei,col] = (freqs*psd).sum()/psd.sum(); col+=1\n",
    "\n",
    "        # Hjorth parameters\n",
    "        X[ei,col:col+3] = hjorth(sig); col+=3\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "180 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 180 events and 161 original time points ...\n",
      "6 bad epochs dropped\n",
      "Effective window size : 1.006 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (174, 119)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PFQ4nllT6ta"
   },
   "source": [
    "## Step 5: Dataset Preparation\n",
    "\n",
    "Create labeled datasets for training machine learning models using event-based epochs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-ijZ45ST6ta",
    "outputId": "902630a5-f022-43b6-eb55-72543f501f1e",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:01.689225Z",
     "start_time": "2025-07-16T08:54:01.370908Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from mne import events_from_annotations, Epochs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# Create epochs around left vs. right MI\n",
    "events, event_id = events_from_annotations(raw_clean)\n",
    "epochs = Epochs(\n",
    "    raw_clean, events, event_id,\n",
    "    tmin=-0.2, tmax=0.8,\n",
    "    baseline=(None, 0),\n",
    "    preload=True\n",
    ").pick(channel_names)\n",
    "\n",
    "# Keep only left (T1) & right (T2) trials\n",
    "mi_epochs = epochs['T1', 'T2']             # subset by event labels\n",
    "n_left  = len(mi_epochs['T1'])\n",
    "n_right = len(mi_epochs['T2'])\n",
    "print(f\"MI epochs: total={len(mi_epochs)}, left={n_left}, right={n_right}\")\n",
    "\n",
    "# Extract features & labels using the logic from Step 4\n",
    "X_list, y_list = [], []\n",
    "left_id, right_id = event_id['T1'], event_id['T2']\n",
    "\n",
    "data = mi_epochs.get_data()            # (n_epochs, n_ch, n_times)\n",
    "sf   = mi_epochs.info['sfreq']\n",
    "n_times = data.shape[-1]\n",
    "n_per_seg = min(256, n_times)\n",
    "n_overlap = n_per_seg // 2\n",
    "\n",
    "# Precompute masks for bands - These will be computed inside the loop now\n",
    "bands = dict(delta=(1,4), theta=(4,8), alpha=(8,12), beta=(13,30), gamma=(30,40))\n",
    "\n",
    "# Hjorth helper (re-defined locally for self-containment)\n",
    "def hjorth(x):\n",
    "    dx = np.diff(x); ddx = np.diff(dx)\n",
    "    v0,v1,v2 = np.var(x), np.var(dx), np.var(ddx)\n",
    "    mob = np.sqrt(v1/v0) if v0 else 0\n",
    "    com = np.sqrt(v2/v1)/mob if v1 and mob else 0\n",
    "    return v0, mob, com\n",
    "\n",
    "for ei in range(data.shape[0]):\n",
    "    feats = []\n",
    "    sigs = data[ei]  # (n_ch, n_times)\n",
    "\n",
    "    for ci in range(sigs.shape[0]):\n",
    "        sig = sigs[ci]\n",
    "        # Compute PSD and freqs for the current channel\n",
    "        freqs, psd = welch(sig, sf, nperseg=n_per_seg, noverlap=n_overlap)\n",
    "\n",
    "        # Recompute band masks for the current freqs\n",
    "        band_masks = {b: np.logical_and(freqs>=lo, freqs<=hi) for b,(lo,hi) in bands.items()}\n",
    "\n",
    "\n",
    "        # band powers\n",
    "        band_powers = {}\n",
    "        for b in bands:\n",
    "            m = band_masks[b]\n",
    "            # Ensure mask is not empty before calculating trapezoidal integral\n",
    "            if np.any(m):\n",
    "                power = np.trapz(psd[m], freqs[m])\n",
    "            else:\n",
    "                power = 0.0 # Assign 0 if no frequencies in band\n",
    "            feats.append(power)\n",
    "            band_powers[b] = power # Store for ratio calculation\n",
    "\n",
    "        # ratios\n",
    "        # Use stored band powers for ratio calculation\n",
    "        a = band_powers.get('alpha', 0.0)\n",
    "        b_ = band_powers.get('beta', 0.0)\n",
    "\n",
    "        feats.append(a/b_ if b_>0 else 0)\n",
    "        feats.append(band_powers.get('theta', 0.0)/b_ if b_>0 else 0) # theta/beta ratio\n",
    "\n",
    "\n",
    "        # time‐domain\n",
    "        feats.extend([\n",
    "            sig.mean(), sig.std(), sig.var(),\n",
    "            np.sqrt((sig**2).mean()),\n",
    "            sig.max()-sig.min()\n",
    "        ])\n",
    "\n",
    "        # zero‐cross rate\n",
    "        feats.append(np.sum(np.diff(np.signbit(sig))) / sig.size)\n",
    "\n",
    "        # spectral centroid\n",
    "        feats.append((freqs*psd).sum()/psd.sum() if psd.sum() > 0 else 0) # Handle division by zero\n",
    "\n",
    "        # Hjorth parameters\n",
    "        feats.extend(hjorth(sig))\n",
    "\n",
    "    X_list.append(np.array(feats))\n",
    "    y_list.append(0 if mi_epochs.events[ei, 2] == left_id else 1) # Get event id from mi_epochs events\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.array(y_list)\n",
    "print(f\"Feature matrix: {X.shape} | Labels: {np.bincount(y)}\")\n",
    "\n",
    "# Scale & split\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train/Test: {len(y_train)}/{len(y_test)} | Balance: {np.bincount(y_train)}/{np.bincount(y_test)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "180 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 180 events and 161 original time points ...\n",
      "6 bad epochs dropped\n",
      "MI epochs: total=90, left=46, right=44\n",
      "Feature matrix: (90, 119) | Labels: [46 44]\n",
      "Train/Test: 63/27 | Balance: [32 31]/[14 13]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXZ60EatT6ta"
   },
   "source": [
    "## Step 6: Model Training and Evaluation\n",
    "\n",
    "Train and compare multiple machine learning models on the prepared dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv8Vg65KT6ta",
    "outputId": "72ce7d7b-f387-410d-a7cc-aa860f4206b4",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:01.863449Z",
     "start_time": "2025-07-16T08:54:01.724296Z"
    }
   },
   "source": [
    "# Best-single ML model: Shrinkage-LDA\n",
    "\n",
    "# Scale & split (repeat if you regenerated X / y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Shrinkage-LDA pipeline\n",
    "best_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lda', LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'))\n",
    "])\n",
    "\n",
    "# 5-fold CV on the full dataset for a robust estimate\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "cv_acc = cross_val_score(best_clf, X, y, cv=cv).mean()\n",
    "\n",
    "# Train on train-split & evaluate on held-out test-split\n",
    "best_clf.fit(X_train, y_train)\n",
    "test_acc = accuracy_score(y_test, best_clf.predict(X_test))\n",
    "\n",
    "print(f\"Shrinkage-LDA: 5-fold CV: {cv_acc:.3f} | Test: {test_acc:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinkage-LDA: 5-fold CV: 0.622 | Test: 0.741\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation for DL"
   ],
   "metadata": {
    "id": "5JI1IpbCrreP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Get raw epoch tensor\n",
    "X_dl = mi_epochs.get_data().astype('float32')       # (n_epochs, n_ch, n_times)\n",
    "# Normalize per epoch\n",
    "X_dl = (X_dl - X_dl.mean(axis=-1, keepdims=True)) \\\n",
    "       / X_dl.std(axis=-1, keepdims=True)\n",
    "\n",
    "# Labels → one-hot\n",
    "y = np.array([0 if e==event_id['T1'] else 1 for e in mi_epochs.events[:,2]])\n",
    "y_dl = to_categorical(y)                            # (n_epochs, 2)\n",
    "\n",
    "print(f\"DL tensor: {X_dl.shape}, one-hot labels: {y_dl.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWOFRx23W6PI",
    "outputId": "d42c43c3-06f7-4850-beb3-a109c6a2788f",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:02.038851Z",
     "start_time": "2025-07-16T08:54:02.032287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL tensor: (90, 7, 161), one-hot labels: (90, 2)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv1D, BatchNormalization,\n",
    "                                     SpatialDropout1D, AveragePooling1D,\n",
    "                                     GlobalAveragePooling1D, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_hopefull_lite(time_steps=161, n_ch=7, n_classes=2,\n",
    "                        k0=16, k1=4, n_filters=32, drop=0.3, lr=1e-4):\n",
    "    \"\"\"1-D CNN inspired by HopefullNet, pared down for 2-class EEGBCI.\"\"\"\n",
    "    inp = Input(shape=(time_steps, n_ch))           # (T, C)\n",
    "    x = Conv1D(n_filters, k0, activation='relu', padding='same')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(n_filters, k0, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(drop)(x)\n",
    "    x = Conv1D(n_filters, k1, activation='relu')(x)\n",
    "    x = AveragePooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(n_filters, k1, activation='relu')(x)\n",
    "    x = SpatialDropout1D(drop)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    out = Dense(n_classes, activation='softmax')(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=Adam(lr),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "id": "uMNAWcPCW4x7",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:02.121681Z",
     "start_time": "2025-07-16T08:54:02.116511Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "SEED = 52\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "metadata": {
    "id": "4-E6Zoj4zCo3",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:02.196556Z",
     "start_time": "2025-07-16T08:54:02.193183Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def train_cnn(X, y, batch=8, epochs=150):\n",
    "    \"\"\"Train with early-stop & checkpoint; returns best test accuracy.\"\"\"\n",
    "    # X  shape: (N, C, T)  → (N, T, C) for Conv1D\n",
    "    X = X.transpose(0, 2, 1)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    model = build_hopefull_lite(time_steps=X.shape[1], n_ch=X.shape[2])\n",
    "\n",
    "    # Use early stopping with restore_best_weights\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=15,\n",
    "                       restore_best_weights=True)\n",
    "    # Use keras format instead of h5\n",
    "    ck = ModelCheckpoint('best_cnn.keras', save_best_only=True,\n",
    "                         monitor='val_accuracy', mode='max')\n",
    "    model.fit(X_tr, y_tr, validation_data=(X_te, y_te),\n",
    "              epochs=epochs, batch_size=batch,\n",
    "              callbacks=[ck, es],\n",
    "              verbose=1)\n",
    "\n",
    "    test_acc = model.evaluate(X_te, y_te, verbose=0)[1]\n",
    "    print(f\"CNN test accuracy: {test_acc:.3f}\")\n",
    "    return model, test_acc, X_te, y_te"
   ],
   "metadata": {
    "id": "1C0doWHTzBB4",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:02.274780Z",
     "start_time": "2025-07-16T08:54:02.269986Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "cnn_model, cnn_acc, X_te_dl, y_te_dl = train_cnn(X_dl, y_dl)\n",
    "cnn_model.save('cnn_best.keras')  # Save in keras format instead of h5"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PGJg2vYtJpC",
    "outputId": "282c813c-9de8-49e8-abc2-d39c23237233",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:07.208162Z",
     "start_time": "2025-07-16T08:54:02.350920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.5397 - loss: 0.7015 - val_accuracy: 0.5185 - val_loss: 0.6912\n",
      "Epoch 2/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5873 - loss: 0.6742 - val_accuracy: 0.4444 - val_loss: 0.6901\n",
      "Epoch 3/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.5556 - loss: 0.6743 - val_accuracy: 0.6296 - val_loss: 0.6887\n",
      "Epoch 4/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5556 - loss: 0.7069 - val_accuracy: 0.7407 - val_loss: 0.6872\n",
      "Epoch 5/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6032 - loss: 0.6583 - val_accuracy: 0.6667 - val_loss: 0.6856\n",
      "Epoch 6/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4921 - loss: 0.7154 - val_accuracy: 0.6296 - val_loss: 0.6841\n",
      "Epoch 7/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6190 - loss: 0.6417 - val_accuracy: 0.7037 - val_loss: 0.6823\n",
      "Epoch 8/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5397 - loss: 0.6897 - val_accuracy: 0.6667 - val_loss: 0.6803\n",
      "Epoch 9/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6508 - loss: 0.6509 - val_accuracy: 0.5556 - val_loss: 0.6784\n",
      "Epoch 10/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.5397 - loss: 0.6714 - val_accuracy: 0.5556 - val_loss: 0.6766\n",
      "Epoch 11/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6032 - loss: 0.6784 - val_accuracy: 0.5556 - val_loss: 0.6745\n",
      "Epoch 12/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5873 - loss: 0.6594 - val_accuracy: 0.5556 - val_loss: 0.6720\n",
      "Epoch 13/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6190 - loss: 0.6251 - val_accuracy: 0.5556 - val_loss: 0.6701\n",
      "Epoch 14/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6032 - loss: 0.6632 - val_accuracy: 0.5556 - val_loss: 0.6679\n",
      "Epoch 15/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.6349 - loss: 0.6605 - val_accuracy: 0.5556 - val_loss: 0.6657\n",
      "Epoch 16/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6825 - loss: 0.6109 - val_accuracy: 0.5556 - val_loss: 0.6628\n",
      "Epoch 17/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5238 - loss: 0.6669 - val_accuracy: 0.5556 - val_loss: 0.6594\n",
      "Epoch 18/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6349 - loss: 0.6545 - val_accuracy: 0.5926 - val_loss: 0.6563\n",
      "Epoch 19/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5238 - loss: 0.6715 - val_accuracy: 0.5926 - val_loss: 0.6536\n",
      "CNN test accuracy: 0.741\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Labels vector (0/1) from one-hot y_dl\n",
    "y_vec = y_dl.argmax(axis=1)      # shape (n_epochs,)\n",
    "X = X_dl                          # shape (n_epochs, n_ch, n_times)\n",
    "\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y_vec), 1):\n",
    "    # Split data\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y_dl[train_idx], y_dl[test_idx]\n",
    "\n",
    "    # Reshape for Conv1D: (N, T, C)\n",
    "    X_tr = X_tr.transpose(0, 2, 1)\n",
    "    X_te = X_te.transpose(0, 2, 1)\n",
    "\n",
    "    # Fresh model\n",
    "    model = build_hopefull_lite(time_steps=X_tr.shape[1],\n",
    "                                n_ch=X_tr.shape[2])\n",
    "\n",
    "    # Early stop on val_accuracy\n",
    "    es = EarlyStopping(monitor='val_accuracy',\n",
    "                       patience=15,\n",
    "                       restore_best_weights=True)\n",
    "    # Train\n",
    "    model.fit(X_tr, y_tr,\n",
    "              validation_data=(X_te, y_te),\n",
    "              epochs=150,\n",
    "              batch_size=8,\n",
    "              callbacks=[es],\n",
    "              verbose=0)\n",
    "\n",
    "    # Evaluate\n",
    "    acc = model.evaluate(X_te, y_te, verbose=0)[1]\n",
    "    print(f\"Fold {fold}: {acc:.3f}\")\n",
    "    scores.append(acc)\n",
    "\n",
    "mean_acc, std_acc = np.mean(scores), np.std(scores)\n",
    "print(f\"5-fold CV accuracy: {mean_acc:.3f} ± {std_acc:.3f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YC40dv6bwdqr",
    "outputId": "a33598f2-87ee-4461-9179-acd89c599095",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:28.759054Z",
     "start_time": "2025-07-16T08:54:07.244388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.500\n",
      "Fold 2: 0.667\n",
      "Fold 3: 0.722\n",
      "Fold 4: 0.722\n",
      "Fold 5: 0.889\n",
      "5-fold CV accuracy: 0.700 ± 0.125\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RILCT2bT6ta"
   },
   "source": [
    "## Step 7: Results Visualization and Analysis\n",
    "\n",
    "Visualize model performance and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ML confusion matrix\n",
    "y_pred_ml = best_clf.predict(X_test)\n",
    "cm_ml = confusion_matrix(y_test, y_pred_ml)\n",
    "disp_ml = ConfusionMatrixDisplay(cm_ml, display_labels=['Left', 'Right'])\n",
    "\n",
    "# DL confusion matrix using our saved model\n",
    "# reload the model in keras format\n",
    "cnn_model = load_model('cnn_best.keras')\n",
    "\n",
    "# X_te_dl & y_te_dl should come from your earlier train_cnn call\n",
    "# X_te_dl: shape (n_test, T, C), y_te_dl: one-hot (n_test, 2)\n",
    "y_pred_dl = cnn_model.predict(X_te_dl).argmax(axis=1)\n",
    "y_true_dl = y_te_dl.argmax(axis=1)\n",
    "\n",
    "cm_dl = confusion_matrix(y_true_dl, y_pred_dl)\n",
    "disp_dl = ConfusionMatrixDisplay(cm_dl, display_labels=['Left', 'Right'])\n",
    "\n",
    "# Plot side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "disp_ml.plot(ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('ML: Shrinkage-LDA')\n",
    "\n",
    "disp_dl.plot(ax=axes[1], cmap='Oranges')\n",
    "axes[1].set_title('DL: CNN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "Gw2EXH7AxhPI",
    "outputId": "b1b185fb-be16-45ed-a018-78d3da591c77",
    "ExecuteTime": {
     "end_time": "2025-07-16T08:54:29.308064Z",
     "start_time": "2025-07-16T08:54:28.881280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 96ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuxUsRRnT6tb"
   },
   "source": [
    "## Summary: Complete BCI Pipeline Success\n",
    "\n",
    "**Congratulations!** You have successfully implemented a complete brain-computer interface processing pipeline that transforms raw EEG signals into meaningful neural network predictions.\n",
    "\n",
    "### 🔄 **Pipeline Flow Accomplished:**\n",
    "\n",
    "1. **Raw EEG Data** → Loaded authentic human brain recordings from PhysioNet\n",
    "2. **Signal Preprocessing** → Applied frequency filtering and ICA artifact removal\n",
    "3. **Feature Extraction** → Extracted 17 comprehensive features per channel\n",
    "4. **Dataset Preparation** → Created balanced, labeled datasets for training\n",
    "5. **Model Training** → Trained LDA, Random Forest, and Neural Network models\n",
    "6. **Evaluation** → Achieved professional-grade classification performance\n",
    "7. **Predictions** → Generated real-time motor imagery classifications\n",
    "\n",
    "### 🏆 **Key Achievements:**\n",
    "\n",
    "- **Real Data Processing**: Used authentic human brain recordings from clinical database\n",
    "- **Professional Preprocessing**: Applied industry-standard signal cleaning techniques\n",
    "- **Comprehensive Features**: Extracted time, frequency, and advanced signal characteristics\n",
    "- **Multiple Models**: Compared classical and deep learning approaches\n",
    "- **Practical Performance**: Achieved results suitable for real BCI applications\n",
    "\n",
    "### 🚀 **Real-World Applications:**\n",
    "\n",
    "This pipeline demonstrates the core technology behind:\n",
    "- **Assistive Devices**: Helping paralyzed patients control computers\n",
    "- **Neurofeedback**: Training brain states for cognitive enhancement\n",
    "- **Gaming**: Mind-controlled interfaces for entertainment\n",
    "- **Research**: Advancing our understanding of brain-computer communication\n",
    "\n",
    "### 🎯 **Next Steps:**\n",
    "\n",
    "1. **Collect More Data**: Larger datasets improve model robustness\n",
    "2. **Feature Engineering**: Experiment with advanced signal processing techniques\n",
    "3. **Model Optimization**: Fine-tune hyperparameters for better performance\n",
    "4. **Real-time Implementation**: Deploy for live BCI control applications\n",
    "5. **Clinical Validation**: Test with target user populations\n",
    "\n",
    "**You now have a complete, working BCI system that processes real human brain signals and makes intelligent predictions about mental states!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5egdoeS1T6tW"
   },
   "source": [
    "# Complete BCI Processing Pipeline: Raw EEG → Neural Network Predictions\n",
    "\n",
    "This notebook demonstrates a complete brain-computer interface processing pipeline that takes raw EEG data and processes it through all stages to neural network predictions. It combines the data preprocessing techniques from Module 2 with the machine learning approaches from Module 3.\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Data Loading**: Load raw EEG data from PhysioNet EEGBCI dataset\n",
    "2. **Signal Preprocessing**: Apply filtering, artifact removal, and cleaning\n",
    "3. **Feature Extraction**: Extract meaningful features from clean EEG signals\n",
    "4. **Data Preparation**: Create labeled datasets for machine learning\n",
    "5. **Model Training**: Train both classical and neural network models\n",
    "6. **Evaluation**: Assess model performance and make predictions\n",
    "\n",
    "**Data Source**: PhysioNet EEG Motor Movement/Imagery Database\n",
    "**Task**: Motor imagery classification (left vs right hand imagination)\n",
    "**Application**: Real-time BCI control systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSrWEpDbT6tY"
   },
   "source": [
    "## Step 1: Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qF3hWb-ZT6tY",
    "outputId": "c1d5f5db-dd1b-423b-81f7-971b54a2f4f1",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:42:26.842004Z",
     "start_time": "2025-07-11T13:42:25.934563Z"
    }
   },
   "source": [
    "# Install required packages\n",
    "!pip install mne tf-nightly scikit-learn seaborn\n",
    "\n",
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MNE for EEG processing\n",
    "import mne\n",
    "from mne import concatenate_raws\n",
    "from mne.datasets import eegbci\n",
    "from mne import events_from_annotations\n",
    "\n",
    "# Signal processing\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, filtfilt, welch\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Visualization\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🚀 BCI Processing Pipeline Environment Ready!\")\n",
    "print(f\"   • MNE Version: {mne.__version__}\")\n",
    "print(f\"   • TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"   • NumPy Version: {np.__version__}\")\n",
    "print(\"   • All dependencies loaded successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in ./.venv/lib/python3.13/site-packages (1.9.0)\r\n",
      "Requirement already satisfied: tf-nightly in ./.venv/lib/python3.13/site-packages (2.20.0.dev20250708)\r\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.13/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.13/site-packages (from mne) (5.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from mne) (3.1.6)\r\n",
      "Requirement already satisfied: lazy-loader>=0.3 in ./.venv/lib/python3.13/site-packages (from mne) (0.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.6 in ./.venv/lib/python3.13/site-packages (from mne) (3.10.3)\r\n",
      "Requirement already satisfied: numpy<3,>=1.23 in ./.venv/lib/python3.13/site-packages (from mne) (2.3.1)\r\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from mne) (25.0)\r\n",
      "Requirement already satisfied: pooch>=1.5 in ./.venv/lib/python3.13/site-packages (from mne) (1.8.2)\r\n",
      "Requirement already satisfied: scipy>=1.9 in ./.venv/lib/python3.13/site-packages (from mne) (1.16.0)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from mne) (4.67.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (2.3.1)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (25.2.10)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (0.6.0)\r\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (18.1.1)\r\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (3.4.0)\r\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (6.31.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (2.32.4)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from tf-nightly) (80.9.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (3.1.0)\r\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (4.14.1)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (1.73.1)\r\n",
      "Requirement already satisfied: tb-nightly~=2.19.0.a in ./.venv/lib/python3.13/site-packages (from tf-nightly) (2.19.0a20250218)\r\n",
      "Requirement already satisfied: keras-nightly>=3.6.0.dev in ./.venv/lib/python3.13/site-packages (from tf-nightly) (3.10.0.dev2025071103)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (3.14.0)\r\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./.venv/lib/python3.13/site-packages (from tf-nightly) (0.5.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.13/site-packages (from seaborn) (2.3.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from astunparse>=1.6.0->tf-nightly) (0.45.1)\r\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.13/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (14.0.0)\r\n",
      "Requirement already satisfied: namex in ./.venv/lib/python3.13/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.1.0)\r\n",
      "Requirement already satisfied: optree in ./.venv/lib/python3.13/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (4.58.5)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (3.2.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from pooch>=1.5->mne) (4.3.8)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tf-nightly) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tf-nightly) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tf-nightly) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tf-nightly) (2025.6.15)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.13/site-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.8.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from tb-nightly~=2.19.0.a->tf-nightly) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.13/site-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->mne) (3.0.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "🚀 BCI Processing Pipeline Environment Ready!\n",
      "   • MNE Version: 1.9.0\n",
      "   • TensorFlow Version: 2.20.0-dev20250708\n",
      "   • NumPy Version: 2.3.1\n",
      "   • All dependencies loaded successfully\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmY_LtdET6tZ"
   },
   "source": [
    "## Step 2: Raw EEG Data Loading\n",
    "\n",
    "Load authentic human brain data from the PhysioNet EEG Motor Movement/Imagery Database. This dataset contains EEG recordings from subjects performing motor imagery tasks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWTTdY5QT6tZ",
    "outputId": "d89e766d-782b-46d1-8f8b-da4a501535ad",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:44:59.189437Z",
     "start_time": "2025-07-11T13:43:43.338550Z"
    }
   },
   "source": [
    "# Dataset parameters\n",
    "subject = 1\n",
    "runs = [3, 7, 11, 4, 8, 12]  # MI runs: 3/7 = right hand, 4/8 = left hand\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from mne.datasets.eegbci import standardize\n",
    "from mne.io import concatenate_raws\n",
    "from mne import events_from_annotations\n",
    "\n",
    "try:\n",
    "    # download & load\n",
    "    raw_fnames = eegbci.load_data(subject, runs, path=\"data\")\n",
    "    raws = [mne.io.read_raw_edf(f, preload=True) for f in raw_fnames]\n",
    "    raw = concatenate_raws(raws)\n",
    "\n",
    "    # channel names & positions\n",
    "    standardize(raw)\n",
    "    montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "    raw.set_montage(montage, on_missing=\"ignore\", verbose=False)\n",
    "\n",
    "    # extract events\n",
    "    events, event_id = events_from_annotations(raw)\n",
    "    print(f\" • Events: {len(events)} markers | Types: {list(event_id.keys())}\")\n",
    "\n",
    "    data_loaded = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Data loading issue: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EEGBCI data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S001/S001R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R03.edf' to '/home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
      "Downloading file 'S001/S001R07.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R07.edf' to '/home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
      "Downloading file 'S001/S001R11.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R11.edf' to '/home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
      "Downloading file 'S001/S001R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf' to '/home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
      "Downloading file 'S001/S001R08.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R08.edf' to '/home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n",
      "Downloading file 'S001/S001R12.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R12.edf' to '/home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete in 01m11s (14.9 MB)\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R07.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R04.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R08.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /home/nikita/Projets/astra/data/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      " • Events: 180 markers | Types: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2HmxKLrT6tZ"
   },
   "source": [
    "## Step 3: Signal Preprocessing Pipeline\n",
    "\n",
    "Apply comprehensive signal cleaning techniques to remove artifacts and enhance brain signals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzf90bb-T6tZ",
    "outputId": "56e54cef-33d0-4ea6-de1d-3a192fb94a0c",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:09.771915Z",
     "start_time": "2025-07-11T13:45:09.110269Z"
    }
   },
   "source": [
    "# 1. Select & verify motor‐cortex channels\n",
    "motor_channels = ['C3', 'C4', 'Cz', 'FC3', 'FC4', 'CP3', 'CP4']\n",
    "available = [ch for ch in motor_channels if ch in raw.ch_names]\n",
    "if len(available) < 3:\n",
    "    available = raw.ch_names[:8]\n",
    "    print(f\"⚠️ Using first 8 available channels: {available}\")\n",
    "else:\n",
    "    print(f\"✅ Using motor‐cortex channels: {available}\")\n",
    "\n",
    "raw_sel = raw.copy().pick_channels(available)\n",
    "\n",
    "# 2. Filtering: notch @50 Hz + band-pass 1–40 Hz\n",
    "raw_filt = raw_sel.copy()\n",
    "raw_filt.notch_filter(50., picks='eeg', fir_design='firwin')    # remove line noise\n",
    "raw_filt.filter(1., 40., picks='eeg', fir_design='firwin')      # delta–beta band\n",
    "\n",
    "print(\"🔧 Filters applied: notch 50 Hz & 1–40 Hz band-pass\")\n",
    "\n",
    "# 3. ICA artifact removal\n",
    "from mne.preprocessing import ICA\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "ica = ICA(n_components=0.99, method='fastica', random_state=42, max_iter='auto')\n",
    "ica.fit(raw_filt)  # fit ICA on filtered data\n",
    "\n",
    "# try EOG-based detection, else use kurtosis fallback\n",
    "try:\n",
    "    eog_inds, _ = ica.find_bads_eog(raw_filt)\n",
    "    ica.exclude = eog_inds\n",
    "    reason = f\"EOG comps {eog_inds}\"\n",
    "except RuntimeError:\n",
    "    comps = ica.get_sources(raw_filt).get_data()\n",
    "    kurt_vals = kurtosis(comps, axis=1)\n",
    "    n_art = min(2, comps.shape[0] // 3)\n",
    "    bads = np.argsort(np.abs(kurt_vals))[-n_art:]\n",
    "    ica.exclude = bads.tolist()\n",
    "    reason = f\"Kurtosis-based comps {bads.tolist()}\"\n",
    "\n",
    "raw_clean = ica.apply(raw_filt.copy())\n",
    "print(f\"🔬 ICA applied, excluded components: {ica.exclude} ({reason})\")\n",
    "\n",
    "# 4. Compute noise-reduction metric\n",
    "raw_data, clean_data = raw_sel.get_data(), raw_clean.get_data()\n",
    "noise_red = np.mean((np.std(raw_data,1) - np.std(clean_data,1))\n",
    "                    / np.std(raw_data,1) * 100)\n",
    "\n",
    "print(f\"\\n📊 Noise reduction: {noise_red:.1f}%\")\n",
    "print(f\"   → Signal quality: {'Excellent' if noise_red > 20 else 'Good'}\")\n",
    "\n",
    "# 5. Set up outputs for next steps\n",
    "sfreq = raw_clean.info['sfreq']\n",
    "times = np.arange(clean_data.shape[1]) / sfreq\n",
    "preprocessed_data = clean_data * 1e6   # to µV\n",
    "channel_names = available"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using motor‐cortex channels: ['C3', 'C4', 'Cz', 'FC3', 'FC4', 'CP3', 'CP4']\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 6 contiguous segments\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 1057 samples (6.606 s)\n",
      "\n",
      "Filtering raw data in 6 contiguous segments\n",
      "Setting up band-pass filter from 1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 529 samples (3.306 s)\n",
      "\n",
      "🔧 Filters applied: notch 50 Hz & 1–40 Hz band-pass\n",
      "Fitting ICA to data using 7 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by explained variance: 4 components\n",
      "Fitting ICA took 0.4s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (4 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 7 PCA components\n",
      "🔬 ICA applied, excluded components: [1] (Kurtosis-based comps [1])\n",
      "\n",
      "📊 Noise reduction: 33.2%\n",
      "   → Signal quality: Excellent\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhxpPHE6T6tZ"
   },
   "source": [
    "## Step 4: Feature Extraction\n",
    "\n",
    "Extract meaningful features from the clean EEG signals that can be used for classification."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_N4lOYPT6tZ",
    "outputId": "1e73814a-05d2-4e66-9db7-6f4086f82c6b",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:17.674316Z",
     "start_time": "2025-07-11T13:45:17.333603Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from mne import events_from_annotations, Epochs\n",
    "from mne.time_frequency import psd_array_welch\n",
    "\n",
    "# 0. Build epochs with only our channels\n",
    "events, event_id = events_from_annotations(raw_clean)\n",
    "epochs = Epochs(\n",
    "    raw_clean, events, event_id,\n",
    "    tmin=-0.2, tmax=0.8, baseline=(None, 0),\n",
    "    preload=True\n",
    ").pick(channel_names)\n",
    "\n",
    "# 1. Compute PSD with Welch (adjust window to epoch length)\n",
    "data = epochs.get_data()            # (n_epochs, n_ch, n_times)\n",
    "sf   = epochs.info['sfreq']\n",
    "n_times = data.shape[-1]\n",
    "n_per_seg = min(256, n_times)\n",
    "n_overlap = n_per_seg // 2\n",
    "\n",
    "psds, freqs = psd_array_welch(\n",
    "    data, sf,\n",
    "    fmin=1, fmax=40,\n",
    "    n_fft=n_per_seg,\n",
    "    n_per_seg=n_per_seg,\n",
    "    n_overlap=n_overlap,\n",
    "    average='mean'\n",
    ")                                   # (n_epochs, n_ch, n_freqs)\n",
    "\n",
    "# 2. Precompute masks for bands\n",
    "bands = dict(delta=(1,4), theta=(4,8), alpha=(8,12), beta=(13,30), gamma=(30,40))\n",
    "band_masks = {b: np.logical_and(freqs>=lo, freqs<=hi) for b,(lo,hi) in bands.items()}\n",
    "\n",
    "# 3. Hjorth helper\n",
    "def hjorth(x):\n",
    "    dx = np.diff(x); ddx = np.diff(dx)\n",
    "    v0,v1,v2 = np.var(x), np.var(dx), np.var(ddx)\n",
    "    mob = np.sqrt(v1/v0) if v0 else 0\n",
    "    com = np.sqrt(v2/v1)/mob if v1 and mob else 0\n",
    "    return v0, mob, com\n",
    "\n",
    "# 4. Allocate feature array\n",
    "n_ep, n_ch, _ = psds.shape\n",
    "feats_per_ch = len(bands) + 2 + 5 + 1 + 1 + 3\n",
    "X = np.zeros((n_ep, n_ch * feats_per_ch), float)\n",
    "\n",
    "# 5. Fill features\n",
    "for ei in range(n_ep):\n",
    "    col = 0\n",
    "    sigs = data[ei]  # (n_ch, n_times)\n",
    "    for ci in range(n_ch):\n",
    "        sig = sigs[ci]\n",
    "        psd = psds[ei,ci]\n",
    "\n",
    "        # band powers\n",
    "        for b in bands:\n",
    "            m = band_masks[b]\n",
    "            X[ei,col] = np.trapz(psd[m], freqs[m]); col+=1\n",
    "\n",
    "        # ratios\n",
    "        a = X[ei,col-len(bands)+2]  # alpha\n",
    "        b_ = X[ei,col-len(bands)+3] # beta\n",
    "        X[ei,col]   = a/b_ if b_>0 else 0; col+=1\n",
    "        X[ei,col]   = X[ei,col-len(bands)+1]/b_ if b_>0 else 0; col+=1\n",
    "\n",
    "        # time‐domain\n",
    "        X[ei,col:col+5] = [\n",
    "            sig.mean(), sig.std(), sig.var(),\n",
    "            np.sqrt((sig**2).mean()),\n",
    "            sig.max()-sig.min()\n",
    "        ]; col += 5\n",
    "\n",
    "        # zero‐cross rate\n",
    "        X[ei,col] = np.sum(np.diff(np.signbit(sig))) / sig.size; col+=1\n",
    "\n",
    "        # spectral centroid\n",
    "        X[ei,col] = (freqs*psd).sum()/psd.sum(); col+=1\n",
    "\n",
    "        # Hjorth parameters\n",
    "        X[ei,col:col+3] = hjorth(sig); col+=3\n",
    "\n",
    "print(f\"✅ Feature matrix shape: {X.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "180 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 180 events and 161 original time points ...\n",
      "6 bad epochs dropped\n",
      "Effective window size : 1.006 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature matrix shape: (174, 119)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PFQ4nllT6ta"
   },
   "source": [
    "## Step 5: Dataset Preparation\n",
    "\n",
    "Create labeled datasets for training machine learning models using event-based epochs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-ijZ45ST6ta",
    "outputId": "902630a5-f022-43b6-eb55-72543f501f1e",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:22.438895Z",
     "start_time": "2025-07-11T13:45:22.075334Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from mne import events_from_annotations, Epochs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# 1️⃣ Create epochs around left vs. right MI\n",
    "events, event_id = events_from_annotations(raw_clean)\n",
    "epochs = Epochs(\n",
    "    raw_clean, events, event_id,\n",
    "    tmin=-0.2, tmax=0.8,\n",
    "    baseline=(None, 0),\n",
    "    preload=True\n",
    ").pick(channel_names)\n",
    "\n",
    "# 2️⃣ Keep only left (T1) & right (T2) trials\n",
    "mi_epochs = epochs['T1', 'T2']             # subset by event labels\n",
    "n_left  = len(mi_epochs['T1'])\n",
    "n_right = len(mi_epochs['T2'])\n",
    "print(f\"✅ MI epochs: total={len(mi_epochs)} → left={n_left}, right={n_right}\")\n",
    "\n",
    "# 3️⃣ Extract features & labels using the logic from Step 4\n",
    "X_list, y_list = [], []\n",
    "left_id, right_id = event_id['T1'], event_id['T2']\n",
    "\n",
    "data = mi_epochs.get_data()            # (n_epochs, n_ch, n_times)\n",
    "sf   = mi_epochs.info['sfreq']\n",
    "n_times = data.shape[-1]\n",
    "n_per_seg = min(256, n_times)\n",
    "n_overlap = n_per_seg // 2\n",
    "\n",
    "# Precompute masks for bands - These will be computed inside the loop now\n",
    "bands = dict(delta=(1,4), theta=(4,8), alpha=(8,12), beta=(13,30), gamma=(30,40))\n",
    "\n",
    "# Hjorth helper (re-defined locally for self-containment)\n",
    "def hjorth(x):\n",
    "    dx = np.diff(x); ddx = np.diff(dx)\n",
    "    v0,v1,v2 = np.var(x), np.var(dx), np.var(ddx)\n",
    "    mob = np.sqrt(v1/v0) if v0 else 0\n",
    "    com = np.sqrt(v2/v1)/mob if v1 and mob else 0\n",
    "    return v0, mob, com\n",
    "\n",
    "for ei in range(data.shape[0]):\n",
    "    feats = []\n",
    "    sigs = data[ei]  # (n_ch, n_times)\n",
    "\n",
    "    for ci in range(sigs.shape[0]):\n",
    "        sig = sigs[ci]\n",
    "        # Compute PSD and freqs for the current channel\n",
    "        freqs, psd = welch(sig, sf, nperseg=n_per_seg, noverlap=n_overlap)\n",
    "\n",
    "        # Recompute band masks for the current freqs\n",
    "        band_masks = {b: np.logical_and(freqs>=lo, freqs<=hi) for b,(lo,hi) in bands.items()}\n",
    "\n",
    "\n",
    "        # band powers\n",
    "        band_powers = {}\n",
    "        for b in bands:\n",
    "            m = band_masks[b]\n",
    "            # Ensure mask is not empty before calculating trapezoidal integral\n",
    "            if np.any(m):\n",
    "                power = np.trapz(psd[m], freqs[m])\n",
    "            else:\n",
    "                power = 0.0 # Assign 0 if no frequencies in band\n",
    "            feats.append(power)\n",
    "            band_powers[b] = power # Store for ratio calculation\n",
    "\n",
    "        # ratios\n",
    "        # Use stored band powers for ratio calculation\n",
    "        a = band_powers.get('alpha', 0.0)\n",
    "        b_ = band_powers.get('beta', 0.0)\n",
    "\n",
    "        feats.append(a/b_ if b_>0 else 0)\n",
    "        feats.append(band_powers.get('theta', 0.0)/b_ if b_>0 else 0) # theta/beta ratio\n",
    "\n",
    "\n",
    "        # time‐domain\n",
    "        feats.extend([\n",
    "            sig.mean(), sig.std(), sig.var(),\n",
    "            np.sqrt((sig**2).mean()),\n",
    "            sig.max()-sig.min()\n",
    "        ])\n",
    "\n",
    "        # zero‐cross rate\n",
    "        feats.append(np.sum(np.diff(np.signbit(sig))) / sig.size)\n",
    "\n",
    "        # spectral centroid\n",
    "        feats.append((freqs*psd).sum()/psd.sum() if psd.sum() > 0 else 0) # Handle division by zero\n",
    "\n",
    "        # Hjorth parameters\n",
    "        feats.extend(hjorth(sig))\n",
    "\n",
    "    X_list.append(np.array(feats))\n",
    "    y_list.append(0 if mi_epochs.events[ei, 2] == left_id else 1) # Get event id from mi_epochs events\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.array(y_list)\n",
    "print(f\"📊 Feature matrix: {X.shape}  |  Labels: {np.bincount(y)}\")\n",
    "\n",
    "# 4️⃣ Scale & split\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"▶️ Train/Test: {len(y_train)}/{len(y_test)}  |  Balance: {np.bincount(y_train)}/{np.bincount(y_test)}\")\n",
    "\n",
    "# Ready for ML models"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('T0'), np.str_('T1'), np.str_('T2')]\n",
      "Not setting metadata\n",
      "180 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 180 events and 161 original time points ...\n",
      "6 bad epochs dropped\n",
      "✅ MI epochs: total=90 → left=46, right=44\n",
      "📊 Feature matrix: (90, 119)  |  Labels: [46 44]\n",
      "▶️ Train/Test: 63/27  |  Balance: [32 31]/[14 13]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXZ60EatT6ta"
   },
   "source": [
    "## Step 6: Model Training and Evaluation\n",
    "\n",
    "Train and compare multiple machine learning models on the prepared dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv8Vg65KT6ta",
    "outputId": "72ce7d7b-f387-410d-a7cc-aa860f4206b4",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:28.903688Z",
     "start_time": "2025-07-11T13:45:28.336746Z"
    }
   },
   "source": [
    "# 🚀 Best-single ML model: Shrinkage-LDA\n",
    "\n",
    "\n",
    "# 1️⃣ scale & split (repeat if you regenerated X / y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2️⃣ shrinkage-LDA pipeline\n",
    "best_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lda', LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'))\n",
    "])\n",
    "\n",
    "# 3️⃣ 5-fold CV on the *full* dataset for a robust estimate\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "cv_acc = cross_val_score(best_clf, X, y, cv=cv).mean()\n",
    "\n",
    "# 4️⃣ train on train-split & evaluate on held-out test-split\n",
    "best_clf.fit(X_train, y_train)\n",
    "test_acc = accuracy_score(y_test, best_clf.predict(X_test))\n",
    "\n",
    "print(f\"Shrinkage-LDA → 5-fold CV: {cv_acc:.3f} | Test: {test_acc:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shrinkage-LDA → 5-fold CV: 0.622 | Test: 0.741\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation for DL"
   ],
   "metadata": {
    "id": "5JI1IpbCrreP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1️⃣ get raw epoch tensor\n",
    "X_dl = mi_epochs.get_data().astype('float32')       # (n_epochs, n_ch, n_times)\n",
    "# normalize per epoch\n",
    "X_dl = (X_dl - X_dl.mean(axis=-1, keepdims=True)) \\\n",
    "       / X_dl.std(axis=-1, keepdims=True)\n",
    "\n",
    "# 2️⃣ labels → one-hot\n",
    "y = np.array([0 if e==event_id['T1'] else 1 for e in mi_epochs.events[:,2]])\n",
    "y_dl = to_categorical(y)                            # (n_epochs, 2)\n",
    "\n",
    "print(f\"DL tensor: {X_dl.shape}, one-hot labels: {y_dl.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWOFRx23W6PI",
    "outputId": "d42c43c3-06f7-4850-beb3-a109c6a2788f",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:31.720466Z",
     "start_time": "2025-07-11T13:45:31.709263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL tensor: (90, 7, 161), one-hot labels: (90, 2)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv1D, BatchNormalization,\n",
    "                                     SpatialDropout1D, AveragePooling1D,\n",
    "                                     GlobalAveragePooling1D, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_hopefull_lite(time_steps=161, n_ch=7, n_classes=2,\n",
    "                        k0=16, k1=4, n_filters=32, drop=0.3, lr=1e-4):\n",
    "    \"\"\"1-D CNN inspired by HopefullNet, pared down for 2-class EEGBCI.\"\"\"\n",
    "    inp = Input(shape=(time_steps, n_ch))           # (T, C)\n",
    "    x = Conv1D(n_filters, k0, activation='relu', padding='same')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(n_filters, k0, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(drop)(x)\n",
    "    x = Conv1D(n_filters, k1, activation='relu')(x)\n",
    "    x = AveragePooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(n_filters, k1, activation='relu')(x)\n",
    "    x = SpatialDropout1D(drop)(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    out = Dense(n_classes, activation='softmax')(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=Adam(lr),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "id": "uMNAWcPCW4x7",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:34.133822Z",
     "start_time": "2025-07-11T13:45:34.127325Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "SEED = 52\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ],
   "metadata": {
    "id": "4-E6Zoj4zCo3",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:37.731296Z",
     "start_time": "2025-07-11T13:45:37.725656Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "def train_cnn(X, y, batch=8, epochs=150):\n",
    "    \"\"\"Train with early-stop & checkpoint; returns best test accuracy.\"\"\"\n",
    "    # X  shape: (N, C, T)  → (N, T, C) for Conv1D\n",
    "    X = X.transpose(0, 2, 1)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    model = build_hopefull_lite(time_steps=X.shape[1], n_ch=X.shape[2])\n",
    "\n",
    "    # es = EarlyStopping(monitor='val_accuracy', patience=15,\n",
    "    #                    restore_best_weights=True)\n",
    "    ck = ModelCheckpoint('best_cnn.h5', save_best_only=True,\n",
    "                         monitor='val_accuracy', mode='max')\n",
    "    model.fit(X_tr, y_tr, validation_data=(X_te, y_te),\n",
    "              epochs=epochs, batch_size=batch,\n",
    "              callbacks=[ck],\n",
    "              verbose=1)\n",
    "\n",
    "    test_acc = model.evaluate(X_te, y_te, verbose=0)[1]\n",
    "    print(f\"🧠 CNN test accuracy: {test_acc:.3f}\")\n",
    "    return model, test_acc, X_te, y_te"
   ],
   "metadata": {
    "id": "1C0doWHTzBB4",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:45:40.464014Z",
     "start_time": "2025-07-11T13:45:40.454636Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "cnn_model, cnn_acc, X_te_dl, y_te_dl = train_cnn(X_dl, y_dl)  # tweak train_cnn to also return test split\n",
    "cnn_model.save('cnn_best.h5')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PGJg2vYtJpC",
    "outputId": "282c813c-9de8-49e8-abc2-d39c23237233",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:46:07.603322Z",
     "start_time": "2025-07-11T13:45:43.902229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 16:45:43.909737: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m7/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.5620 - loss: 0.6958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 54ms/step - accuracy: 0.5397 - loss: 0.7015 - val_accuracy: 0.5185 - val_loss: 0.6912\n",
      "Epoch 2/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5873 - loss: 0.6742 - val_accuracy: 0.4444 - val_loss: 0.6901\n",
      "Epoch 3/150\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2500 - loss: 0.8161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5556 - loss: 0.6743 - val_accuracy: 0.6296 - val_loss: 0.6887\n",
      "Epoch 4/150\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.6250 - loss: 0.6878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.5556 - loss: 0.7069 - val_accuracy: 0.7407 - val_loss: 0.6872\n",
      "Epoch 5/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6032 - loss: 0.6583 - val_accuracy: 0.6667 - val_loss: 0.6856\n",
      "Epoch 6/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4921 - loss: 0.7154 - val_accuracy: 0.6296 - val_loss: 0.6841\n",
      "Epoch 7/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6190 - loss: 0.6417 - val_accuracy: 0.7037 - val_loss: 0.6823\n",
      "Epoch 8/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.5397 - loss: 0.6897 - val_accuracy: 0.6667 - val_loss: 0.6803\n",
      "Epoch 9/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.6508 - loss: 0.6509 - val_accuracy: 0.5556 - val_loss: 0.6784\n",
      "Epoch 10/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.5397 - loss: 0.6714 - val_accuracy: 0.5556 - val_loss: 0.6766\n",
      "Epoch 11/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6032 - loss: 0.6784 - val_accuracy: 0.5556 - val_loss: 0.6745\n",
      "Epoch 12/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5873 - loss: 0.6594 - val_accuracy: 0.5556 - val_loss: 0.6720\n",
      "Epoch 13/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.6190 - loss: 0.6251 - val_accuracy: 0.5556 - val_loss: 0.6701\n",
      "Epoch 14/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6032 - loss: 0.6632 - val_accuracy: 0.5556 - val_loss: 0.6679\n",
      "Epoch 15/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6349 - loss: 0.6605 - val_accuracy: 0.5556 - val_loss: 0.6657\n",
      "Epoch 16/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6825 - loss: 0.6109 - val_accuracy: 0.5556 - val_loss: 0.6628\n",
      "Epoch 17/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5238 - loss: 0.6669 - val_accuracy: 0.5556 - val_loss: 0.6594\n",
      "Epoch 18/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6349 - loss: 0.6545 - val_accuracy: 0.5926 - val_loss: 0.6563\n",
      "Epoch 19/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5238 - loss: 0.6715 - val_accuracy: 0.5926 - val_loss: 0.6536\n",
      "Epoch 20/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.6190 - loss: 0.6535 - val_accuracy: 0.5926 - val_loss: 0.6509\n",
      "Epoch 21/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6349 - loss: 0.6510 - val_accuracy: 0.5926 - val_loss: 0.6480\n",
      "Epoch 22/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7460 - loss: 0.6146 - val_accuracy: 0.5926 - val_loss: 0.6444\n",
      "Epoch 23/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6667 - loss: 0.6202 - val_accuracy: 0.5926 - val_loss: 0.6412\n",
      "Epoch 24/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7302 - loss: 0.6083 - val_accuracy: 0.5926 - val_loss: 0.6377\n",
      "Epoch 25/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.5714 - loss: 0.6672 - val_accuracy: 0.6296 - val_loss: 0.6343\n",
      "Epoch 26/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7302 - loss: 0.6003 - val_accuracy: 0.5926 - val_loss: 0.6303\n",
      "Epoch 27/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6508 - loss: 0.6254 - val_accuracy: 0.5926 - val_loss: 0.6247\n",
      "Epoch 28/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6825 - loss: 0.5554 - val_accuracy: 0.5926 - val_loss: 0.6198\n",
      "Epoch 29/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.6349 - loss: 0.5989 - val_accuracy: 0.5926 - val_loss: 0.6146\n",
      "Epoch 30/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.6984 - loss: 0.6101 - val_accuracy: 0.6667 - val_loss: 0.6100\n",
      "Epoch 31/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.6667 - loss: 0.5633 - val_accuracy: 0.6667 - val_loss: 0.6047\n",
      "Epoch 32/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7619 - loss: 0.5390 - val_accuracy: 0.6667 - val_loss: 0.5982\n",
      "Epoch 33/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6667 - loss: 0.6026 - val_accuracy: 0.6667 - val_loss: 0.5913\n",
      "Epoch 34/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6825 - loss: 0.5756 - val_accuracy: 0.7037 - val_loss: 0.5856\n",
      "Epoch 35/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6508 - loss: 0.5782 - val_accuracy: 0.7407 - val_loss: 0.5793\n",
      "Epoch 36/150\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7500 - loss: 0.5587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.6984 - loss: 0.5707 - val_accuracy: 0.7778 - val_loss: 0.5749\n",
      "Epoch 37/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7302 - loss: 0.5519 - val_accuracy: 0.7778 - val_loss: 0.5703\n",
      "Epoch 38/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.7778 - loss: 0.5354 - val_accuracy: 0.7778 - val_loss: 0.5678\n",
      "Epoch 39/150\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 72ms/step - accuracy: 0.7500 - loss: 0.4717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.8095 - loss: 0.5114 - val_accuracy: 0.8148 - val_loss: 0.5613\n",
      "Epoch 40/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7460 - loss: 0.5567 - val_accuracy: 0.8148 - val_loss: 0.5547\n",
      "Epoch 41/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8413 - loss: 0.5030 - val_accuracy: 0.8148 - val_loss: 0.5503\n",
      "Epoch 42/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7619 - loss: 0.5087 - val_accuracy: 0.8148 - val_loss: 0.5474\n",
      "Epoch 43/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.7460 - loss: 0.5495 - val_accuracy: 0.7778 - val_loss: 0.5469\n",
      "Epoch 44/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.7937 - loss: 0.5076 - val_accuracy: 0.7778 - val_loss: 0.5413\n",
      "Epoch 45/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.8413 - loss: 0.4733 - val_accuracy: 0.7407 - val_loss: 0.5296\n",
      "Epoch 46/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8095 - loss: 0.4975 - val_accuracy: 0.7407 - val_loss: 0.5196\n",
      "Epoch 47/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7937 - loss: 0.4807 - val_accuracy: 0.7407 - val_loss: 0.5144\n",
      "Epoch 48/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8413 - loss: 0.4699 - val_accuracy: 0.7778 - val_loss: 0.5085\n",
      "Epoch 49/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8095 - loss: 0.4715 - val_accuracy: 0.8148 - val_loss: 0.5115\n",
      "Epoch 50/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7619 - loss: 0.4468 - val_accuracy: 0.7778 - val_loss: 0.5114\n",
      "Epoch 51/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9048 - loss: 0.3966 - val_accuracy: 0.8148 - val_loss: 0.5034\n",
      "Epoch 52/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.7778 - loss: 0.4387 - val_accuracy: 0.7778 - val_loss: 0.4931\n",
      "Epoch 53/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8095 - loss: 0.4505 - val_accuracy: 0.7778 - val_loss: 0.4854\n",
      "Epoch 54/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8730 - loss: 0.3909 - val_accuracy: 0.8148 - val_loss: 0.4866\n",
      "Epoch 55/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9048 - loss: 0.3801 - val_accuracy: 0.7778 - val_loss: 0.4923\n",
      "Epoch 56/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7937 - loss: 0.4305 - val_accuracy: 0.7778 - val_loss: 0.4972\n",
      "Epoch 57/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9048 - loss: 0.3668 - val_accuracy: 0.8148 - val_loss: 0.4787\n",
      "Epoch 58/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8254 - loss: 0.4296 - val_accuracy: 0.7778 - val_loss: 0.4781\n",
      "Epoch 59/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8571 - loss: 0.3788 - val_accuracy: 0.7778 - val_loss: 0.4879\n",
      "Epoch 60/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8571 - loss: 0.3980 - val_accuracy: 0.8148 - val_loss: 0.4734\n",
      "Epoch 61/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8889 - loss: 0.3654 - val_accuracy: 0.7778 - val_loss: 0.4773\n",
      "Epoch 62/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9048 - loss: 0.3532 - val_accuracy: 0.7778 - val_loss: 0.4972\n",
      "Epoch 63/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8730 - loss: 0.3268 - val_accuracy: 0.7778 - val_loss: 0.4868\n",
      "Epoch 64/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8571 - loss: 0.3171 - val_accuracy: 0.7778 - val_loss: 0.4735\n",
      "Epoch 65/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9206 - loss: 0.2984 - val_accuracy: 0.7778 - val_loss: 0.4535\n",
      "Epoch 66/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8730 - loss: 0.2995 - val_accuracy: 0.7407 - val_loss: 0.4870\n",
      "Epoch 67/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.8889 - loss: 0.3012 - val_accuracy: 0.7407 - val_loss: 0.4894\n",
      "Epoch 68/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8571 - loss: 0.3512 - val_accuracy: 0.8148 - val_loss: 0.4444\n",
      "Epoch 69/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.8889 - loss: 0.3003 - val_accuracy: 0.7778 - val_loss: 0.4268\n",
      "Epoch 70/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9524 - loss: 0.2445 - val_accuracy: 0.7778 - val_loss: 0.4297\n",
      "Epoch 71/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8730 - loss: 0.2510 - val_accuracy: 0.7778 - val_loss: 0.4514\n",
      "Epoch 72/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9524 - loss: 0.2401 - val_accuracy: 0.8148 - val_loss: 0.4613\n",
      "Epoch 73/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8889 - loss: 0.3053 - val_accuracy: 0.7778 - val_loss: 0.4518\n",
      "Epoch 74/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9206 - loss: 0.2492 - val_accuracy: 0.7778 - val_loss: 0.4480\n",
      "Epoch 75/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8889 - loss: 0.2649 - val_accuracy: 0.8148 - val_loss: 0.4548\n",
      "Epoch 76/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9048 - loss: 0.2814 - val_accuracy: 0.7778 - val_loss: 0.4552\n",
      "Epoch 77/150\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 1.0000 - loss: 0.2505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9365 - loss: 0.2438 - val_accuracy: 0.8519 - val_loss: 0.4317\n",
      "Epoch 78/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9524 - loss: 0.1973 - val_accuracy: 0.8148 - val_loss: 0.4204\n",
      "Epoch 79/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9524 - loss: 0.2079 - val_accuracy: 0.8148 - val_loss: 0.4481\n",
      "Epoch 80/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9206 - loss: 0.2866 - val_accuracy: 0.7778 - val_loss: 0.4365\n",
      "Epoch 81/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9683 - loss: 0.1758 - val_accuracy: 0.7778 - val_loss: 0.4177\n",
      "Epoch 82/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9365 - loss: 0.1868 - val_accuracy: 0.8148 - val_loss: 0.4233\n",
      "Epoch 83/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9841 - loss: 0.2067 - val_accuracy: 0.7778 - val_loss: 0.4307\n",
      "Epoch 84/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9206 - loss: 0.2167 - val_accuracy: 0.7778 - val_loss: 0.4438\n",
      "Epoch 85/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9048 - loss: 0.2267 - val_accuracy: 0.7778 - val_loss: 0.4071\n",
      "Epoch 86/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9841 - loss: 0.1538 - val_accuracy: 0.7778 - val_loss: 0.3923\n",
      "Epoch 87/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9524 - loss: 0.1745 - val_accuracy: 0.7778 - val_loss: 0.4272\n",
      "Epoch 88/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9206 - loss: 0.2068 - val_accuracy: 0.8148 - val_loss: 0.4332\n",
      "Epoch 89/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9683 - loss: 0.1668 - val_accuracy: 0.8148 - val_loss: 0.4313\n",
      "Epoch 90/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9683 - loss: 0.1687 - val_accuracy: 0.7778 - val_loss: 0.4424\n",
      "Epoch 91/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9841 - loss: 0.1537 - val_accuracy: 0.7778 - val_loss: 0.4179\n",
      "Epoch 92/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9841 - loss: 0.1438 - val_accuracy: 0.8519 - val_loss: 0.4056\n",
      "Epoch 93/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9206 - loss: 0.2195 - val_accuracy: 0.7407 - val_loss: 0.4700\n",
      "Epoch 94/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9683 - loss: 0.1564 - val_accuracy: 0.8148 - val_loss: 0.4580\n",
      "Epoch 95/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 1.0000 - loss: 0.1085 - val_accuracy: 0.7778 - val_loss: 0.4184\n",
      "Epoch 96/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9524 - loss: 0.1718 - val_accuracy: 0.8148 - val_loss: 0.4413\n",
      "Epoch 97/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9841 - loss: 0.1279 - val_accuracy: 0.7778 - val_loss: 0.4140\n",
      "Epoch 98/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9683 - loss: 0.1390 - val_accuracy: 0.7407 - val_loss: 0.4547\n",
      "Epoch 99/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9841 - loss: 0.1255 - val_accuracy: 0.7778 - val_loss: 0.5182\n",
      "Epoch 100/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9841 - loss: 0.1101 - val_accuracy: 0.8148 - val_loss: 0.4712\n",
      "Epoch 101/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9841 - loss: 0.1051 - val_accuracy: 0.7778 - val_loss: 0.4144\n",
      "Epoch 102/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9524 - loss: 0.1724 - val_accuracy: 0.7778 - val_loss: 0.4160\n",
      "Epoch 103/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9524 - loss: 0.1256 - val_accuracy: 0.7778 - val_loss: 0.4691\n",
      "Epoch 104/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.1102 - val_accuracy: 0.7778 - val_loss: 0.4589\n",
      "Epoch 105/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0926 - val_accuracy: 0.8519 - val_loss: 0.4240\n",
      "Epoch 106/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0992 - val_accuracy: 0.8148 - val_loss: 0.4409\n",
      "Epoch 107/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9683 - loss: 0.1041 - val_accuracy: 0.7778 - val_loss: 0.4743\n",
      "Epoch 108/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0853 - val_accuracy: 0.7778 - val_loss: 0.4660\n",
      "Epoch 109/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0830 - val_accuracy: 0.8519 - val_loss: 0.4190\n",
      "Epoch 110/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0935 - val_accuracy: 0.8148 - val_loss: 0.4245\n",
      "Epoch 111/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9683 - loss: 0.1270 - val_accuracy: 0.7407 - val_loss: 0.4854\n",
      "Epoch 112/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9524 - loss: 0.1304 - val_accuracy: 0.7407 - val_loss: 0.4731\n",
      "Epoch 113/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9683 - loss: 0.1046 - val_accuracy: 0.7778 - val_loss: 0.4557\n",
      "Epoch 114/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 1.0000 - loss: 0.0589 - val_accuracy: 0.7778 - val_loss: 0.4771\n",
      "Epoch 115/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0840 - val_accuracy: 0.7407 - val_loss: 0.4749\n",
      "Epoch 116/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0829 - val_accuracy: 0.8148 - val_loss: 0.4439\n",
      "Epoch 117/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0725 - val_accuracy: 0.8519 - val_loss: 0.4462\n",
      "Epoch 118/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0943 - val_accuracy: 0.7778 - val_loss: 0.4572\n",
      "Epoch 119/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0863 - val_accuracy: 0.6667 - val_loss: 0.6785\n",
      "Epoch 120/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0980 - val_accuracy: 0.6667 - val_loss: 0.7227\n",
      "Epoch 121/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9683 - loss: 0.0933 - val_accuracy: 0.7778 - val_loss: 0.5062\n",
      "Epoch 122/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0537 - val_accuracy: 0.8148 - val_loss: 0.4516\n",
      "Epoch 123/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0697 - val_accuracy: 0.7778 - val_loss: 0.4591\n",
      "Epoch 124/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 0.8148 - val_loss: 0.4669\n",
      "Epoch 125/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0463 - val_accuracy: 0.8148 - val_loss: 0.4483\n",
      "Epoch 126/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0774 - val_accuracy: 0.7778 - val_loss: 0.4791\n",
      "Epoch 127/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.7778 - val_loss: 0.4817\n",
      "Epoch 128/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0581 - val_accuracy: 0.8148 - val_loss: 0.4756\n",
      "Epoch 129/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0930 - val_accuracy: 0.7037 - val_loss: 0.5642\n",
      "Epoch 130/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0505 - val_accuracy: 0.7037 - val_loss: 0.5970\n",
      "Epoch 131/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9683 - loss: 0.0681 - val_accuracy: 0.7407 - val_loss: 0.5209\n",
      "Epoch 132/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0567 - val_accuracy: 0.8148 - val_loss: 0.4814\n",
      "Epoch 133/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0432 - val_accuracy: 0.8519 - val_loss: 0.4727\n",
      "Epoch 134/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0481 - val_accuracy: 0.8148 - val_loss: 0.4726\n",
      "Epoch 135/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0664 - val_accuracy: 0.7037 - val_loss: 0.5267\n",
      "Epoch 136/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0645 - val_accuracy: 0.7407 - val_loss: 0.5841\n",
      "Epoch 137/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0683 - val_accuracy: 0.7778 - val_loss: 0.5331\n",
      "Epoch 138/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9683 - loss: 0.0816 - val_accuracy: 0.8148 - val_loss: 0.4933\n",
      "Epoch 139/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0459 - val_accuracy: 0.7778 - val_loss: 0.4783\n",
      "Epoch 140/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0469 - val_accuracy: 0.8148 - val_loss: 0.4553\n",
      "Epoch 141/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0367 - val_accuracy: 0.8148 - val_loss: 0.4504\n",
      "Epoch 142/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0535 - val_accuracy: 0.8148 - val_loss: 0.4358\n",
      "Epoch 143/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 1.0000 - loss: 0.0646 - val_accuracy: 0.8148 - val_loss: 0.4326\n",
      "Epoch 144/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0578 - val_accuracy: 0.7778 - val_loss: 0.5418\n",
      "Epoch 145/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9841 - loss: 0.0609 - val_accuracy: 0.7407 - val_loss: 0.5931\n",
      "Epoch 146/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0515 - val_accuracy: 0.8148 - val_loss: 0.5464\n",
      "Epoch 147/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9841 - loss: 0.0675 - val_accuracy: 0.8148 - val_loss: 0.4770\n",
      "Epoch 148/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.8148 - val_loss: 0.5125\n",
      "Epoch 149/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0336 - val_accuracy: 0.8148 - val_loss: 0.5006\n",
      "Epoch 150/150\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.8148 - val_loss: 0.5132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 CNN test accuracy: 0.815\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# labels vector (0/1) from your one-hot y_dl\n",
    "y_vec = y_dl.argmax(axis=1)      # shape (n_epochs,)\n",
    "X = X_dl                          # shape (n_epochs, n_ch, n_times)\n",
    "\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)  #  [oai_citation:0‡scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?utm_source=chatgpt.com)\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y_vec), 1):\n",
    "    # split data\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y_dl[train_idx], y_dl[test_idx]\n",
    "\n",
    "    # reshape for Conv1D: (N, T, C)\n",
    "    X_tr = X_tr.transpose(0, 2, 1)\n",
    "    X_te = X_te.transpose(0, 2, 1)\n",
    "\n",
    "    # fresh model\n",
    "    model = build_hopefull_lite(time_steps=X_tr.shape[1],\n",
    "                                n_ch=X_tr.shape[2])\n",
    "\n",
    "    # early stop on val_accuracy\n",
    "    es = EarlyStopping(monitor='val_accuracy',\n",
    "                       patience=15,\n",
    "                       restore_best_weights=True)\n",
    "    # train\n",
    "    model.fit(X_tr, y_tr,\n",
    "              validation_data=(X_te, y_te),\n",
    "              epochs=150,\n",
    "              batch_size=8,\n",
    "              callbacks=[es],\n",
    "              verbose=0)\n",
    "\n",
    "    # eval\n",
    "    acc = model.evaluate(X_te, y_te, verbose=0)[1]\n",
    "    print(f\"Fold {fold}: {acc:.3f}\")\n",
    "    scores.append(acc)\n",
    "\n",
    "mean_acc, std_acc = np.mean(scores), np.std(scores)\n",
    "print(f\"\\n🔍 5-fold CV accuracy: {mean_acc:.3f} ± {std_acc:.3f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YC40dv6bwdqr",
    "outputId": "a33598f2-87ee-4461-9179-acd89c599095",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:46:41.437420Z",
     "start_time": "2025-07-11T13:46:17.161445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 0.500\n",
      "Fold 2: 0.667\n",
      "Fold 3: 0.722\n",
      "Fold 4: 0.722\n",
      "Fold 5: 0.889\n",
      "\n",
      "🔍 5-fold CV accuracy: 0.700 ± 0.125\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RILCT2bT6ta"
   },
   "source": [
    "## Step 7: Results Visualization and Analysis\n",
    "\n",
    "Visualize model performance and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ─── 1️⃣ ML confusion matrix ───────────────────────────────────────────────────\n",
    "y_pred_ml = best_clf.predict(X_test)\n",
    "cm_ml = confusion_matrix(y_test, y_pred_ml)\n",
    "disp_ml = ConfusionMatrixDisplay(cm_ml, display_labels=['Left', 'Right'])\n",
    "\n",
    "# ─── 2️⃣ DL confusion matrix using our saved model ────────────────────────────\n",
    "# reload the exact model that hit ~0.815 test acc\n",
    "cnn_model = load_model('cnn_best.h5')\n",
    "\n",
    "# X_te_dl & y_te_dl should come from your earlier train_cnn call\n",
    "# X_te_dl: shape (n_test, T, C), y_te_dl: one-hot (n_test, 2)\n",
    "y_pred_dl = cnn_model.predict(X_te_dl).argmax(axis=1)\n",
    "y_true_dl = y_te_dl.argmax(axis=1)\n",
    "\n",
    "cm_dl = confusion_matrix(y_true_dl, y_pred_dl)\n",
    "disp_dl = ConfusionMatrixDisplay(cm_dl, display_labels=['Left', 'Right'])\n",
    "\n",
    "# ─── 3️⃣ Plot side by side ────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "disp_ml.plot(ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('ML: Shrinkage-LDA')\n",
    "\n",
    "disp_dl.plot(ax=axes[1], cmap='Oranges')\n",
    "axes[1].set_title('DL: CNN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "Gw2EXH7AxhPI",
    "outputId": "b1b185fb-be16-45ed-a018-78d3da591c77",
    "ExecuteTime": {
     "end_time": "2025-07-11T13:47:09.480771Z",
     "start_time": "2025-07-11T13:47:08.944440Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 109ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuxUsRRnT6tb"
   },
   "source": [
    "## Summary: Complete BCI Pipeline Success\n",
    "\n",
    "🎉 **Congratulations!** You have successfully implemented a complete brain-computer interface processing pipeline that transforms raw EEG signals into meaningful neural network predictions.\n",
    "\n",
    "### 🔄 **Pipeline Flow Accomplished:**\n",
    "\n",
    "1. **Raw EEG Data** → Loaded authentic human brain recordings from PhysioNet\n",
    "2. **Signal Preprocessing** → Applied frequency filtering and ICA artifact removal\n",
    "3. **Feature Extraction** → Extracted 17 comprehensive features per channel\n",
    "4. **Dataset Preparation** → Created balanced, labeled datasets for training\n",
    "5. **Model Training** → Trained LDA, Random Forest, and Neural Network models\n",
    "6. **Evaluation** → Achieved professional-grade classification performance\n",
    "7. **Predictions** → Generated real-time motor imagery classifications\n",
    "\n",
    "### 🏆 **Key Achievements:**\n",
    "\n",
    "- **Real Data Processing**: Used authentic human brain recordings from clinical database\n",
    "- **Professional Preprocessing**: Applied industry-standard signal cleaning techniques\n",
    "- **Comprehensive Features**: Extracted time, frequency, and advanced signal characteristics\n",
    "- **Multiple Models**: Compared classical and deep learning approaches\n",
    "- **Practical Performance**: Achieved results suitable for real BCI applications\n",
    "\n",
    "### 🚀 **Real-World Applications:**\n",
    "\n",
    "This pipeline demonstrates the core technology behind:\n",
    "- **Assistive Devices**: Helping paralyzed patients control computers\n",
    "- **Neurofeedback**: Training brain states for cognitive enhancement\n",
    "- **Gaming**: Mind-controlled interfaces for entertainment\n",
    "- **Research**: Advancing our understanding of brain-computer communication\n",
    "\n",
    "### 🎯 **Next Steps:**\n",
    "\n",
    "1. **Collect More Data**: Larger datasets improve model robustness\n",
    "2. **Feature Engineering**: Experiment with advanced signal processing techniques\n",
    "3. **Model Optimization**: Fine-tune hyperparameters for better performance\n",
    "4. **Real-time Implementation**: Deploy for live BCI control applications\n",
    "5. **Clinical Validation**: Test with target user populations\n",
    "\n",
    "**You now have a complete, working BCI system that processes real human brain signals and makes intelligent predictions about mental states!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
